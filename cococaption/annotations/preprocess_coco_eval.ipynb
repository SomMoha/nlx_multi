{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8d968f9e-c7a7-471a-a113-ec473079748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f1f4ca19-20ed-44ba-9ec5-32bf718e712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = {\n",
    "    \"aint\": \"ain't\", \"arent\": \"aren't\", \"cant\": \"can't\", \"couldve\":\n",
    "    \"could've\", \"couldnt\": \"couldn't\", \"couldn'tve\": \"couldn't've\",\n",
    "    \"couldnt've\": \"couldn't've\", \"didnt\": \"didn't\", \"doesnt\":\n",
    "    \"doesn't\", \"dont\": \"don't\", \"hadnt\": \"hadn't\", \"hadnt've\":\n",
    "    \"hadn't've\", \"hadn'tve\": \"hadn't've\", \"hasnt\": \"hasn't\", \"havent\":\n",
    "    \"haven't\", \"hed\": \"he'd\", \"hed've\": \"he'd've\", \"he'dve\":\n",
    "    \"he'd've\", \"hes\": \"he's\", \"howd\": \"how'd\", \"howll\": \"how'll\",\n",
    "    \"hows\": \"how's\", \"Id've\": \"I'd've\", \"I'dve\": \"I'd've\", \"Im\":\n",
    "    \"I'm\", \"Ive\": \"I've\", \"isnt\": \"isn't\", \"itd\": \"it'd\", \"itd've\":\n",
    "    \"it'd've\", \"it'dve\": \"it'd've\", \"itll\": \"it'll\", \"let's\": \"let's\",\n",
    "    \"maam\": \"ma'am\", \"mightnt\": \"mightn't\", \"mightnt've\":\n",
    "    \"mightn't've\", \"mightn'tve\": \"mightn't've\", \"mightve\": \"might've\",\n",
    "    \"mustnt\": \"mustn't\", \"mustve\": \"must've\", \"neednt\": \"needn't\",\n",
    "    \"notve\": \"not've\", \"oclock\": \"o'clock\", \"oughtnt\": \"oughtn't\",\n",
    "    \"ow's'at\": \"'ow's'at\", \"'ows'at\": \"'ow's'at\", \"'ow'sat\":\n",
    "    \"'ow's'at\", \"shant\": \"shan't\", \"shed've\": \"she'd've\", \"she'dve\":\n",
    "    \"she'd've\", \"she's\": \"she's\", \"shouldve\": \"should've\", \"shouldnt\":\n",
    "    \"shouldn't\", \"shouldnt've\": \"shouldn't've\", \"shouldn'tve\":\n",
    "    \"shouldn't've\", \"somebody'd\": \"somebodyd\", \"somebodyd've\":\n",
    "    \"somebody'd've\", \"somebody'dve\": \"somebody'd've\", \"somebodyll\":\n",
    "    \"somebody'll\", \"somebodys\": \"somebody's\", \"someoned\": \"someone'd\",\n",
    "    \"someoned've\": \"someone'd've\", \"someone'dve\": \"someone'd've\",\n",
    "    \"someonell\": \"someone'll\", \"someones\": \"someone's\", \"somethingd\":\n",
    "    \"something'd\", \"somethingd've\": \"something'd've\", \"something'dve\":\n",
    "    \"something'd've\", \"somethingll\": \"something'll\", \"thats\":\n",
    "    \"that's\", \"thered\": \"there'd\", \"thered've\": \"there'd've\",\n",
    "    \"there'dve\": \"there'd've\", \"therere\": \"there're\", \"theres\":\n",
    "    \"there's\", \"theyd\": \"they'd\", \"theyd've\": \"they'd've\", \"they'dve\":\n",
    "    \"they'd've\", \"theyll\": \"they'll\", \"theyre\": \"they're\", \"theyve\":\n",
    "    \"they've\", \"twas\": \"'twas\", \"wasnt\": \"wasn't\", \"wed've\":\n",
    "    \"we'd've\", \"we'dve\": \"we'd've\", \"weve\": \"we've\", \"werent\":\n",
    "    \"weren't\", \"whatll\": \"what'll\", \"whatre\": \"what're\", \"whats\":\n",
    "    \"what's\", \"whatve\": \"what've\", \"whens\": \"when's\", \"whered\":\n",
    "    \"where'd\", \"wheres\": \"where's\", \"whereve\": \"where've\", \"whod\":\n",
    "    \"who'd\", \"whod've\": \"who'd've\", \"who'dve\": \"who'd've\", \"wholl\":\n",
    "    \"who'll\", \"whos\": \"who's\", \"whove\": \"who've\", \"whyll\": \"why'll\",\n",
    "    \"whyre\": \"why're\", \"whys\": \"why's\", \"wont\": \"won't\", \"wouldve\":\n",
    "    \"would've\", \"wouldnt\": \"wouldn't\", \"wouldnt've\": \"wouldn't've\",\n",
    "    \"wouldn'tve\": \"wouldn't've\", \"yall\": \"y'all\", \"yall'll\":\n",
    "    \"y'all'll\", \"y'allll\": \"y'all'll\", \"yall'd've\": \"y'all'd've\",\n",
    "    \"y'alld've\": \"y'all'd've\", \"y'all'dve\": \"y'all'd've\", \"youd\":\n",
    "    \"you'd\", \"youd've\": \"you'd've\", \"you'dve\": \"you'd've\", \"youll\":\n",
    "    \"you'll\", \"youre\": \"you're\", \"youve\": \"you've\"\n",
    "}\n",
    "\n",
    "manual_map = {'none': '0',\n",
    "              'zero': '0',\n",
    "              'one': '1',\n",
    "              'two': '2',\n",
    "              'three': '3',\n",
    "              'four': '4',\n",
    "              'five': '5',\n",
    "              'six': '6',\n",
    "              'seven': '7',\n",
    "              'eight': '8',\n",
    "               'nine': '9',\n",
    "              'ten': '10'}\n",
    "articles = ['a', 'an', 'the']\n",
    "period_strip = re.compile(\"(?!<=\\d)(\\.)(?!\\d)\")\n",
    "comma_strip = re.compile(\"(\\d)(\\,)(\\d)\")\n",
    "punct = [';', r\"/\", '[', ']', '\"', '{', '}',\n",
    "                '(', ')', '=', '+', '\\\\', '_', '-',\n",
    "                '>', '<', '@', '`', ',', '?', '!']\n",
    "\n",
    "def process_punctuation(inText):\n",
    "    outText = inText\n",
    "    for p in punct:\n",
    "        if (p + ' ' in inText or ' ' + p in inText) \\\n",
    "           or (re.search(comma_strip, inText) != None):\n",
    "            outText = outText.replace(p, '')\n",
    "        else:\n",
    "            outText = outText.replace(p, ' ')\n",
    "    outText = period_strip.sub(\"\", outText, re.UNICODE)\n",
    "    return outText\n",
    "\n",
    "\n",
    "def process_digit_article(inText):\n",
    "    outText = []\n",
    "    tempText = inText.lower().split()\n",
    "    for word in tempText:\n",
    "        word = manual_map.setdefault(word, word)\n",
    "        if word not in articles:\n",
    "            outText.append(word)\n",
    "        else:\n",
    "            pass\n",
    "    for wordId, word in enumerate(outText):\n",
    "        if word in contractions:\n",
    "            outText[wordId] = contractions[word]\n",
    "    outText = ' '.join(outText)\n",
    "    return outText\n",
    "\n",
    "\n",
    "def prep_ans(answer):\n",
    "    answer = process_digit_article(process_punctuation(answer))\n",
    "    answer = answer.replace(',', '')\n",
    "    return answer\n",
    "\n",
    "\n",
    "def proc_ans(ans):\n",
    "    ans_prob_dict = {}\n",
    "\n",
    "    for ans_ in ans:\n",
    "        # Check if ans_ is a dictionary and has an 'answer' key\n",
    "        if isinstance(ans_, dict) and \"answer\" in ans_:\n",
    "            ans_proc = prep_ans(ans_[\"answer\"])\n",
    "            if ans_proc not in ans_prob_dict:\n",
    "                ans_prob_dict[ans_proc] = 1\n",
    "            else:\n",
    "                ans_prob_dict[ans_proc] += 1\n",
    "        else:\n",
    "            # Handle the case where ans_ is not a dictionary or does not have an 'answer' key\n",
    "            print(\"Unexpected data type or structure in 'answers':\", ans_)\n",
    "            continue\n",
    "\n",
    "    if ans_prob_dict:\n",
    "        confident_answer = max(ans_prob_dict, key=ans_prob_dict.get)\n",
    "        return confident_answer\n",
    "    else:\n",
    "        # Handle the case when ans_prob_dict is empty\n",
    "        print(\"No valid answers processed\")\n",
    "        return None  # or any appropriate default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4256ffa2-5fb9-4d65-a71c-9e0bb467ca33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a82be310-9bf5-437f-90ba-2c7744ad5c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90a127b0-915b-49d5-83e9-c0274dc7549c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "E:/Download/myProject/Scripts/nle_data/nle_data_test.json\n",
      "the asserton was succefull!!\n",
      "wrote to  E:/Download/myProject/Scripts/cococaption/annotations/multiVqa_test_annot_exp.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "From ruotian luo\n",
    "Create a reference json file used for evaluation with `coco-caption` repo.\n",
    "Used when multiple evaluation captions exist for a single image\n",
    "\"\"\"\n",
    "# Explanations only\n",
    "\n",
    "correct_pth = \"E:/Download/myProject/Scripts/nle_data/nle_data_test.json\"\n",
    "# split = 'test'\n",
    "in_path =\"E:/Download/myProject/Scripts/nle_data/nle_data_test.json\"\n",
    "print(type(in_path))\n",
    "print(in_path)\n",
    "assert correct_pth == in_path\n",
    "print(\"the asserton was succefull!!\")\n",
    "out_path = \"E:/Download/myProject/Scripts/cococaption/annotations/multiVqa_test_annot_exp.json\"\n",
    "data = json.load(open(in_path, 'r'))\n",
    "\n",
    "out = {'info': {'description': 'This is stable 1.0 version of the 2014 MS COCO dataset.', 'url': 'http://mscoco.org', 'version': '1.0', 'year': 2014, 'contributor': 'Microsoft COCO group', 'date_created': '2015-01-27 09:11:52.357475'}, 'licenses': [{'url': 'http://creativecommons.org/licenses/by-nc-sa/2.0/', 'id': 1, 'name': 'Attribution-NonCommercial-ShareAlike License'}, {'url': 'http://creativecommons.org/licenses/by-nc/2.0/', 'id': 2, 'name': 'Attribution-NonCommercial License'}, {'url': 'http://creativecommons.org/licenses/by-nc-nd/2.0/', 'id': 3, 'name': 'Attribution-NonCommercial-NoDerivs License'}, {'url': 'http://creativecommons.org/licenses/by/2.0/', 'id': 4, 'name': 'Attribution License'}, {'url': 'http://creativecommons.org/licenses/by-sa/2.0/', 'id': 5, 'name': 'Attribution-ShareAlike License'}, {'url': 'http://creativecommons.org/licenses/by-nd/2.0/', 'id': 6, 'name': 'Attribution-NoDerivs License'}, {'url': 'http://flickr.com/commons/usage/', 'id': 7, 'name': 'No known copyright restrictions'}, {'url': 'http://www.usa.gov/copyright.shtml', 'id': 8, 'name': 'United States Government Work'}], 'type': 'captions'}\n",
    "out.update({'images': [], 'annotations': []})\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for qid, qid_data in data.items():\n",
    "    \n",
    "    out['images'].append({'id': int(qid)})\n",
    "    \n",
    "    for s in qid_data['explanation']:\n",
    "        \n",
    "        if len(s) == 0:\n",
    "            print(\"Warning: {} has no annotations\".format(qid))\n",
    "            continue\n",
    "            \n",
    "        out['annotations'].append({'image_id': out['images'][-1]['id'], 'caption': s, 'id': cnt})\n",
    "        cnt += 1\n",
    "\n",
    "json.dump(out, open(out_path, 'w'))\n",
    "print('wrote to ', out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aacefafc-3fd6-4466-8906-f8fabbd94154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote to  E:/Download/myProject/Scripts/cococaption/annotations/multiVqa_test_annot_full.json\n"
     ]
    }
   ],
   "source": [
    "# Explanations + Answers\n",
    "\n",
    "in_path = \"E:/Download/myProject/Scripts/nle_data/nle_data_test.json\"\n",
    "out_path = \"E:/Download/myProject/Scripts/cococaption/annotations/multiVqa_test_annot_full.json\"\n",
    "\n",
    "data = json.load(open(in_path, 'r'))\n",
    "\n",
    "out = {'info': {'description': 'This is stable 1.0 version of the 2014 MS COCO dataset.', 'url': 'http://mscoco.org', 'version': '1.0', 'year': 2014, 'contributor': 'Microsoft COCO group', 'date_created': '2015-01-27 09:11:52.357475'}, 'licenses': [{'url': 'http://creativecommons.org/licenses/by-nc-sa/2.0/', 'id': 1, 'name': 'Attribution-NonCommercial-ShareAlike License'}, {'url': 'http://creativecommons.org/licenses/by-nc/2.0/', 'id': 2, 'name': 'Attribution-NonCommercial License'}, {'url': 'http://creativecommons.org/licenses/by-nc-nd/2.0/', 'id': 3, 'name': 'Attribution-NonCommercial-NoDerivs License'}, {'url': 'http://creativecommons.org/licenses/by/2.0/', 'id': 4, 'name': 'Attribution License'}, {'url': 'http://creativecommons.org/licenses/by-sa/2.0/', 'id': 5, 'name': 'Attribution-ShareAlike License'}, {'url': 'http://creativecommons.org/licenses/by-nd/2.0/', 'id': 6, 'name': 'Attribution-NoDerivs License'}, {'url': 'http://flickr.com/commons/usage/', 'id': 7, 'name': 'No known copyright restrictions'}, {'url': 'http://www.usa.gov/copyright.shtml', 'id': 8, 'name': 'United States Government Work'}], 'type': 'captions'}\n",
    "out.update({'images': [], 'annotations': []})\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for qid, qid_data in data.items():\n",
    "    \n",
    "    out['images'].append({'id': int(qid)})\n",
    "    for s in qid_data['explanation']:\n",
    "        \n",
    "        if len(s) == 0:\n",
    "            print(\"Warning: {} has no annotations\".format(qid))\n",
    "            continue\n",
    "        # Processed an    \n",
    "        processed_answer = proc_ans(qid_data['answers'])\n",
    "        if processed_answer is not None:\n",
    "            s = processed_answer + \" because \" + s\n",
    "            out['annotations'].append({'image_id': out['images'][-1]['id'], 'caption': s, 'id': cnt})\n",
    "            cnt += 1\n",
    "        else:\n",
    "            print(\"Could not process answer for QID:\", qid)\n",
    "\n",
    "json.dump(out, open(out_path, 'w'))\n",
    "print('wrote to ', out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "612ff0f0-b479-4141-aea3-59988217e310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for qid, qid_data in data.items():\n",
    "#     proc_ans(qid_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
